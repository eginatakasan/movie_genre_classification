{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import namedtuple\n",
    "from itertools import groupby\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read subtitles file, and convert to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_parse_subtitle(pathdir):\n",
    "    with open(pathdir, 'rb') as f:\n",
    "        res = [list(g) for b,g in groupby(f, lambda x: bool(x.strip())) if b]\n",
    "\n",
    "    Subtitle = namedtuple('Subtitle', 'number start end content at_minute at_seconds')\n",
    "\n",
    "    subs = []\n",
    "    number = 0\n",
    "    for sub in res:\n",
    "        if len(sub) >= 3: # not strictly necessary, but better safe than sorry\n",
    "            sub = [x.strip() for x in sub]\n",
    "            try:\n",
    "                number = sub[0].decode(\"UTF-8\")\n",
    "            except:\n",
    "                number += 1\n",
    "            start_end = sub[1].decode(\"UTF-8\")\n",
    "            content = sub[2]\n",
    "            if len(start_end.split(' --> ')) == 2:\n",
    "                start, end = start_end.split(' --> ') # e.g. 02:14:53,085\n",
    "\n",
    "                if len(start) >= 12 and len(end) >= 12:\n",
    "                    start = start[:12] #for truncating unnecessary fields, if any\n",
    "                    end = end[:12] #for truncating unnecessary fields, if any\n",
    "                    try:\n",
    "                        at_minute = int(start[:2]) * 60 + int(start[3:5])\n",
    "                        at_seconds = int(start[:2]) * 3600 + int(start[3:5]) * 60 + int(start[6:8])\n",
    "                    except:\n",
    "                        at_minute = 0\n",
    "                        at_seconds = 0\n",
    "                        #continue\n",
    "                    subs.append(Subtitle(number, start, end, content, at_minute, at_seconds))\n",
    "\n",
    "    return subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_title(title_name):\n",
    "    result = title_name.replace(' (IMPAIRED).srt', '') \n",
    "    result = result.replace('\"', '')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subtitles(dirs):\n",
    "    directory = [dirname[0] for dirname in os.walk(dirs)][1:]\n",
    "    \n",
    "    for dirname in directory:\n",
    "        filelist = [filename for filename in os.listdir(dirname)]\n",
    "        print(len(filelist))\n",
    "        for filename in filelist:\n",
    "            pathdir = (dirname + '/' + filename)\n",
    "            subs = load_and_parse_subtitle(pathdir)\n",
    "            \n",
    "            if len(subs) <= 0:\n",
    "                continue\n",
    "            word_count = 0\n",
    "            for sub in subs:\n",
    "                word_count += len(str(sub.content).split(\" \"))\n",
    "\n",
    "            movie_time_minute = 60 * int(subs[-1].start.split(\":\")[0]) + int(subs[-2].start.split(\":\")[1])\n",
    "#             print(process_title(filename), subs[-1].start.split(\":\"), subs[-1].start.split(\":\"))\n",
    "\n",
    "            word_per_minute = word_count / movie_time_minute\n",
    "            dialog_per_minute = len(subs) / movie_time_minute\n",
    "\n",
    "            tmp = {'title': process_title(filename), 'word per min': word_per_minute, 'dialog_per_min': dialog_per_minute,\n",
    "                   'genre': dirname.split('/')[1]}\n",
    "            datasets.append(tmp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n",
      "583\n",
      "601\n",
      "609\n",
      "600\n",
      "252\n",
      "462\n",
      "588\n",
      "444\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "process_subtitles('Subtitles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = pd.DataFrame(datasets).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(df):\n",
    "    df['title'] = df['title'].str.replace('[^\\w\\s]', '')\n",
    "    df['title'] = df['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_title(df):\n",
    "    remove_punc(df)\n",
    "    df['title'] = df['title'].str.lower()\n",
    "    df['tokenized_title'] = df.apply(lambda row: nltk.word_tokenize(row['title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ori.copy()\n",
    "df.drop_duplicates(subset='title')\n",
    "preprocess_title(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>word per min</th>\n",
       "      <th>dialog_per_min</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jersey Girl</td>\n",
       "      <td>75.148515</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Jersey Girl</td>\n",
       "      <td>75.148515</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title  word per min  dialog_per_min    genre\n",
       "5    Jersey Girl     75.148515            15.0   Comedy\n",
       "230  Jersey Girl     75.148515            15.0  Romance"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori[df_ori['title']=='Jersey Girl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Romance      609\n",
       "Comedy       598\n",
       "Horror       595\n",
       "Action       586\n",
       "War          579\n",
       "Crime        496\n",
       "Musical      462\n",
       "Western      444\n",
       "Adventure    245\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainTestSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='genre')\n",
    "y = df['genre']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Horror       491\n",
       "Romance      486\n",
       "Action       481\n",
       "Comedy       480\n",
       "War          465\n",
       "Crime        387\n",
       "Musical      364\n",
       "Western      347\n",
       "Adventure    190\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "model = Word2Vec(df, size=150, window=10, min_count=2, workers=10, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "def tfidf(dataset_train, dataset_test):\n",
    "#     print(dataset_train.shape)\n",
    "    vectorizer = TfidfVectorizer(input='content')\n",
    "    features_transformed = vectorizer.fit_transform(dataset_train['title'])\n",
    "    features_test_transformed = vectorizer.transform(dataset_test['title'])\n",
    "    df_tfidf = pd.DataFrame(features_transformed.toarray(), columns=vectorizer.get_feature_names())\n",
    "    df_tfidf_test = pd.DataFrame(features_test_transformed.toarray(), columns=vectorizer.get_feature_names())\n",
    "#     print(df_tfidf.shape)\n",
    "    new_df = dataset_train.drop(['title', 'tokenized_title'], axis=1).reset_index(drop=True)\n",
    "    new_test_df = dataset_test.drop(['title', 'tokenized_title'], axis=1).reset_index(drop=True)\n",
    "#     print(new_df.shape)\n",
    "    df_tfidf = pd.concat([df_tfidf, new_df], axis=1)\n",
    "    df_tfidf_test = pd.concat([df_tfidf_test, new_test_df], axis=1)\n",
    "#     print(df_tfidf.shape)\n",
    "    return df_tfidf, df_tfidf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tfidf_train, tfidf_test = tfidf(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(C=100)\n",
    "classifier.fit(tfidf_train, y_train)\n",
    "y_pred = classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.22      0.16      0.19       141\n",
      "   Adventure       0.00      0.00      0.00         0\n",
      "      Comedy       0.61      0.24      0.34       302\n",
      "       Crime       0.00      0.00      0.00         0\n",
      "      Horror       0.61      0.23      0.34       272\n",
      "     Musical       0.32      0.84      0.46        37\n",
      "     Romance       0.25      0.21      0.23       145\n",
      "         War       0.07      0.35      0.12        23\n",
      "     Western       0.03      1.00      0.06         3\n",
      "\n",
      "    accuracy                           0.25       923\n",
      "   macro avg       0.23      0.34      0.19       923\n",
      "weighted avg       0.47      0.25      0.30       923\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivianni/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3691, 2287]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-299-5a58f2256fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"learning_rate must be greater than zero\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     89\u001b[0m                             \u001b[0mallow_nd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                             y_numeric=is_regressor(self))\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3691, 2287]"
     ]
    }
   ],
   "source": [
    "classifier = AdaBoostClassifier(n_estimators=100)\n",
    "classifier.fit(tfidf_train, y_train)\n",
    "y_pred = classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.05      0.16      0.07        31\n",
      "   Adventure       0.05      0.14      0.08        21\n",
      "      Comedy       0.72      0.22      0.34       389\n",
      "       Crime       0.00      0.00      0.00         1\n",
      "      Horror       0.66      0.20      0.30       351\n",
      "     Musical       0.33      0.84      0.47        38\n",
      "     Romance       0.03      0.40      0.06        10\n",
      "         War       0.23      0.81      0.36        32\n",
      "     Western       0.39      0.76      0.52        50\n",
      "\n",
      "    accuracy                           0.28       923\n",
      "   macro avg       0.27      0.39      0.24       923\n",
      "weighted avg       0.60      0.28      0.32       923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining with movie plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>word per min</th>\n",
       "      <th>dialog_per_min</th>\n",
       "      <th>genre</th>\n",
       "      <th>tokenized_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mash hawkeye</td>\n",
       "      <td>73.541667</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>War</td>\n",
       "      <td>[mash, hawkeye]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr  mrs smith srt</td>\n",
       "      <td>71.666667</td>\n",
       "      <td>13.720430</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>[mr, mrs, smith, srt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>game of thrones the wars to come</td>\n",
       "      <td>54.660000</td>\n",
       "      <td>13.920000</td>\n",
       "      <td>Romance</td>\n",
       "      <td>[game, of, thrones, the, wars, to, come]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ninja assassin</td>\n",
       "      <td>37.933333</td>\n",
       "      <td>8.811111</td>\n",
       "      <td>Crime</td>\n",
       "      <td>[ninja, assassin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the boy</td>\n",
       "      <td>50.021978</td>\n",
       "      <td>12.021978</td>\n",
       "      <td>Horror</td>\n",
       "      <td>[the, boy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>dilwale dulhania le jayenge</td>\n",
       "      <td>37.505319</td>\n",
       "      <td>7.558511</td>\n",
       "      <td>Musical</td>\n",
       "      <td>[dilwale, dulhania, le, jayenge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>hell on wheels timshel</td>\n",
       "      <td>47.642857</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>Western</td>\n",
       "      <td>[hell, on, wheels, timshel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18453</th>\n",
       "      <td>war and remembrance part i</td>\n",
       "      <td>53.022388</td>\n",
       "      <td>13.179104</td>\n",
       "      <td>War</td>\n",
       "      <td>[war, and, remembrance, part, i]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18454</th>\n",
       "      <td>dawn of the dead</td>\n",
       "      <td>42.121212</td>\n",
       "      <td>10.676768</td>\n",
       "      <td>Action</td>\n",
       "      <td>[dawn, of, the, dead]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18455</th>\n",
       "      <td>men in black 3</td>\n",
       "      <td>69.088235</td>\n",
       "      <td>17.862745</td>\n",
       "      <td>Action</td>\n",
       "      <td>[men, in, black, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18456 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  word per min  dialog_per_min  \\\n",
       "0                          mash hawkeye     73.541667       16.750000   \n",
       "1                     mr  mrs smith srt     71.666667       13.720430   \n",
       "2      game of thrones the wars to come     54.660000       13.920000   \n",
       "3                        ninja assassin     37.933333        8.811111   \n",
       "4                               the boy     50.021978       12.021978   \n",
       "...                                 ...           ...             ...   \n",
       "18451       dilwale dulhania le jayenge     37.505319        7.558511   \n",
       "18452            hell on wheels timshel     47.642857       11.333333   \n",
       "18453        war and remembrance part i     53.022388       13.179104   \n",
       "18454                  dawn of the dead     42.121212       10.676768   \n",
       "18455                    men in black 3     69.088235       17.862745   \n",
       "\n",
       "         genre                           tokenized_title  \n",
       "0          War                           [mash, hawkeye]  \n",
       "1       Comedy                     [mr, mrs, smith, srt]  \n",
       "2      Romance  [game, of, thrones, the, wars, to, come]  \n",
       "3        Crime                         [ninja, assassin]  \n",
       "4       Horror                                [the, boy]  \n",
       "...        ...                                       ...  \n",
       "18451  Musical          [dilwale, dulhania, le, jayenge]  \n",
       "18452  Western               [hell, on, wheels, timshel]  \n",
       "18453      War          [war, and, remembrance, part, i]  \n",
       "18454   Action                     [dawn, of, the, dead]  \n",
       "18455   Action                       [men, in, black, 3]  \n",
       "\n",
       "[18456 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pd.read_csv('wiki_movie_plots.csv')[['Title','Genre','Plot', 'Origin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>unknown</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>unknown</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>unknown</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>unknown</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34881</th>\n",
       "      <td>The Water Diviner</td>\n",
       "      <td>unknown</td>\n",
       "      <td>The film begins in 1919, just after World War ...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34882</th>\n",
       "      <td>Çalgı Çengi İkimiz</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Two musicians, Salih and Gürkan, described the...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34883</th>\n",
       "      <td>Olanlar Oldu</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Zafer, a sailor living with his mother Döndü i...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34884</th>\n",
       "      <td>Non-Transferable</td>\n",
       "      <td>romantic comedy</td>\n",
       "      <td>The film centres around a young woman named Am...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34885</th>\n",
       "      <td>İstanbul Kırmızısı</td>\n",
       "      <td>romantic</td>\n",
       "      <td>The writer Orhan Şahin returns to İstanbul aft...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34886 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title            Genre  \\\n",
       "0                Kansas Saloon Smashers          unknown   \n",
       "1         Love by the Light of the Moon          unknown   \n",
       "2               The Martyred Presidents          unknown   \n",
       "3      Terrible Teddy, the Grizzly King          unknown   \n",
       "4                Jack and the Beanstalk          unknown   \n",
       "...                                 ...              ...   \n",
       "34881                 The Water Diviner          unknown   \n",
       "34882                Çalgı Çengi İkimiz           comedy   \n",
       "34883                      Olanlar Oldu           comedy   \n",
       "34884                  Non-Transferable  romantic comedy   \n",
       "34885                İstanbul Kırmızısı         romantic   \n",
       "\n",
       "                                                    Plot    Origin  \n",
       "0      A bartender is working at a saloon, serving dr...  American  \n",
       "1      The moon, painted with a smiling face hangs ov...  American  \n",
       "2      The film, just over a minute long, is composed...  American  \n",
       "3      Lasting just 61 seconds and consisting of two ...  American  \n",
       "4      The earliest known adaptation of the classic f...  American  \n",
       "...                                                  ...       ...  \n",
       "34881  The film begins in 1919, just after World War ...   Turkish  \n",
       "34882  Two musicians, Salih and Gürkan, described the...   Turkish  \n",
       "34883  Zafer, a sailor living with his mother Döndü i...   Turkish  \n",
       "34884  The film centres around a young woman named Am...   Turkish  \n",
       "34885  The writer Orhan Şahin returns to İstanbul aft...   Turkish  \n",
       "\n",
       "[34886 rows x 4 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.rename(columns = {'Title':'title', 'Genre':'genre', \n",
    "                              'Plot':'plot', 'Origin':'origin'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_plot = df_plot[df_plot['origin']=='American']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['American', 'Australian', 'Bangladeshi', 'British', 'Canadian',\n",
       "       ' or Up with Dead People', 'Chinese', 'Egyptian', 'Hong Kong',\n",
       "       'Filipino', 'Assamese', 'Bengali', 'Bollywood', 'Kannada',\n",
       "       'Malayalam', 'Marathi', 'Punjabi', 'Tamil', 'Telugu', 'Japanese',\n",
       "       'Gate: Fuka Ryōiki no Déjà vu', 'Malaysian', 'Maldivian',\n",
       "       'Russian', 'South_Korean', 'Turkish'], dtype=object)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plot['origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_plot[(df_plot['origin']=='American') | (df_plot['origin']=='British')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_plot = df_plot.groupby('title').agg({'genre':'first', 'origin': 'first',\n",
    "                             'plot': '. '.join}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df = df_plot[df_plot.title.isin(df_ori.title.values)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>origin</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'71</td>\n",
       "      <td>unknown</td>\n",
       "      <td>British</td>\n",
       "      <td>Gary Hook, a new recruit to the British Army, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Cloverfield Lane</td>\n",
       "      <td>science fiction psychological thriller</td>\n",
       "      <td>American</td>\n",
       "      <td>After breaking up with her boyfriend Ben, Mich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Things I Hate About You</td>\n",
       "      <td>romantic comedy</td>\n",
       "      <td>American</td>\n",
       "      <td>Cameron James, a new student at Padua High Sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100 Rifles</td>\n",
       "      <td>western</td>\n",
       "      <td>American</td>\n",
       "      <td>In 1912 Sonora, Mexico, African American Lyede...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101 Dalmatians II: Patch's London Adventure</td>\n",
       "      <td>animated</td>\n",
       "      <td>American</td>\n",
       "      <td>The Radcliffe family and their 101 Dalmatians ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>Your Highness</td>\n",
       "      <td>comedy, fantasy</td>\n",
       "      <td>American</td>\n",
       "      <td>Thadeous and Fabious are sons of King Tallious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>Youth in Revolt</td>\n",
       "      <td>comedy-drama</td>\n",
       "      <td>American</td>\n",
       "      <td>Shy, socially inept teenager Nick Twisp lives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>Zelig</td>\n",
       "      <td>mockumentary</td>\n",
       "      <td>American</td>\n",
       "      <td>Set in the 1920s and 1930s, the film focuses o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>Zookeeper</td>\n",
       "      <td>comedy, family</td>\n",
       "      <td>American</td>\n",
       "      <td>A zookeeper named Griffin Keyes (Kevin James) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>Zootopia</td>\n",
       "      <td>animation adventure</td>\n",
       "      <td>American</td>\n",
       "      <td>In a world populated by anthropomorphic mammal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2205 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  \\\n",
       "0                                             '71   \n",
       "1                             10 Cloverfield Lane   \n",
       "2                      10 Things I Hate About You   \n",
       "3                                      100 Rifles   \n",
       "4     101 Dalmatians II: Patch's London Adventure   \n",
       "...                                           ...   \n",
       "2200                                Your Highness   \n",
       "2201                              Youth in Revolt   \n",
       "2202                                        Zelig   \n",
       "2203                                    Zookeeper   \n",
       "2204                                     Zootopia   \n",
       "\n",
       "                                       genre    origin  \\\n",
       "0                                    unknown   British   \n",
       "1     science fiction psychological thriller  American   \n",
       "2                            romantic comedy  American   \n",
       "3                                    western  American   \n",
       "4                                   animated  American   \n",
       "...                                      ...       ...   \n",
       "2200                         comedy, fantasy  American   \n",
       "2201                            comedy-drama  American   \n",
       "2202                            mockumentary  American   \n",
       "2203                          comedy, family  American   \n",
       "2204                     animation adventure  American   \n",
       "\n",
       "                                                   plot  \n",
       "0     Gary Hook, a new recruit to the British Army, ...  \n",
       "1     After breaking up with her boyfriend Ben, Mich...  \n",
       "2     Cameron James, a new student at Padua High Sch...  \n",
       "3     In 1912 Sonora, Mexico, African American Lyede...  \n",
       "4     The Radcliffe family and their 101 Dalmatians ...  \n",
       "...                                                 ...  \n",
       "2200  Thadeous and Fabious are sons of King Tallious...  \n",
       "2201  Shy, socially inept teenager Nick Twisp lives ...  \n",
       "2202  Set in the 1920s and 1930s, the film focuses o...  \n",
       "2203  A zookeeper named Griffin Keyes (Kevin James) ...  \n",
       "2204  In a world populated by anthropomorphic mammal...  \n",
       "\n",
       "[2205 rows x 4 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df = rslt_df.drop(columns='genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_ori, rslt_df, on=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>word per min</th>\n",
       "      <th>dialog_per_min</th>\n",
       "      <th>genre</th>\n",
       "      <th>origin</th>\n",
       "      <th>plot</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Crimson Tide</td>\n",
       "      <td>58.057143</td>\n",
       "      <td>13.933333</td>\n",
       "      <td>War</td>\n",
       "      <td>American</td>\n",
       "      <td>in post soviet russia  civil war erupts as a r...</td>\n",
       "      <td>post soviet russia civil war erupts result ong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Return of a Man Called Horse</td>\n",
       "      <td>15.275000</td>\n",
       "      <td>3.775000</td>\n",
       "      <td>Western</td>\n",
       "      <td>American</td>\n",
       "      <td>trappers with government support force the yel...</td>\n",
       "      <td>trapper government support force yellow hand s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lone Wolf McQuade</td>\n",
       "      <td>30.878788</td>\n",
       "      <td>7.030303</td>\n",
       "      <td>Western</td>\n",
       "      <td>American</td>\n",
       "      <td>the main character  j j  mcquade  norris   is ...</td>\n",
       "      <td>main character j j mcquade norris former marin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Edge of Tomorrow</td>\n",
       "      <td>83.841121</td>\n",
       "      <td>17.429907</td>\n",
       "      <td>Action</td>\n",
       "      <td>American</td>\n",
       "      <td>in       an alien race called mimics arrive in...</td>\n",
       "      <td>alien race called mimic arrive germany storm c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Edge of Tomorrow</td>\n",
       "      <td>83.841121</td>\n",
       "      <td>17.429907</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>American</td>\n",
       "      <td>in       an alien race called mimics arrive in...</td>\n",
       "      <td>alien race called mimic arrive germany storm c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>Closer</td>\n",
       "      <td>57.350000</td>\n",
       "      <td>17.530000</td>\n",
       "      <td>Romance</td>\n",
       "      <td>American</td>\n",
       "      <td>in the opening scene     year old  alice ayres...</td>\n",
       "      <td>opening scene year old alice ayres portman dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>High Plains Drifter</td>\n",
       "      <td>45.805825</td>\n",
       "      <td>9.475728</td>\n",
       "      <td>Western</td>\n",
       "      <td>American</td>\n",
       "      <td>a mysterious stranger rides out of the desert ...</td>\n",
       "      <td>mysterious stranger ride desert isolated minin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>Blown Away</td>\n",
       "      <td>50.054545</td>\n",
       "      <td>11.709091</td>\n",
       "      <td>Action</td>\n",
       "      <td>American</td>\n",
       "      <td>after her mother dies in a mysterious car acci...</td>\n",
       "      <td>mother dy mysterious car accident year old meg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>Ghost Town</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>10.062500</td>\n",
       "      <td>Western</td>\n",
       "      <td>American</td>\n",
       "      <td>the film begins as married new york city busin...</td>\n",
       "      <td>film begin married new york city businessman f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>Tamara Drewe</td>\n",
       "      <td>64.952830</td>\n",
       "      <td>15.716981</td>\n",
       "      <td>Romance</td>\n",
       "      <td>British</td>\n",
       "      <td>set in ewedown  a fictitious village in dorset...</td>\n",
       "      <td>set ewedown fictitious village dorset england ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2766 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  word per min  dialog_per_min  \\\n",
       "12                        Crimson Tide     58.057143       13.933333   \n",
       "13    The Return of a Man Called Horse     15.275000        3.775000   \n",
       "14                   Lone Wolf McQuade     30.878788        7.030303   \n",
       "15                    Edge of Tomorrow     83.841121       17.429907   \n",
       "16                    Edge of Tomorrow     83.841121       17.429907   \n",
       "...                                ...           ...             ...   \n",
       "2773                            Closer     57.350000       17.530000   \n",
       "2774               High Plains Drifter     45.805825        9.475728   \n",
       "2775                        Blown Away     50.054545       11.709091   \n",
       "2776                        Ghost Town     34.400000       10.062500   \n",
       "2777                      Tamara Drewe     64.952830       15.716981   \n",
       "\n",
       "          genre    origin                                               plot  \\\n",
       "12          War  American  in post soviet russia  civil war erupts as a r...   \n",
       "13      Western  American  trappers with government support force the yel...   \n",
       "14      Western  American  the main character  j j  mcquade  norris   is ...   \n",
       "15       Action  American  in       an alien race called mimics arrive in...   \n",
       "16    Adventure  American  in       an alien race called mimics arrive in...   \n",
       "...         ...       ...                                                ...   \n",
       "2773    Romance  American  in the opening scene     year old  alice ayres...   \n",
       "2774    Western  American  a mysterious stranger rides out of the desert ...   \n",
       "2775     Action  American  after her mother dies in a mysterious car acci...   \n",
       "2776    Western  American  the film begins as married new york city busin...   \n",
       "2777    Romance   British  set in ewedown  a fictitious village in dorset...   \n",
       "\n",
       "                                         tokenized_text  \n",
       "12    post soviet russia civil war erupts result ong...  \n",
       "13    trapper government support force yellow hand s...  \n",
       "14    main character j j mcquade norris former marin...  \n",
       "15    alien race called mimic arrive germany storm c...  \n",
       "16    alien race called mimic arrive germany storm c...  \n",
       "...                                                 ...  \n",
       "2773  opening scene year old alice ayres portman dan...  \n",
       "2774  mysterious stranger ride desert isolated minin...  \n",
       "2775  mother dy mysterious car accident year old meg...  \n",
       "2776  film begin married new york city businessman f...  \n",
       "2777  set ewedown fictitious village dorset england ...  \n",
       "\n",
       "[2766 rows x 7 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge[12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>word per min</th>\n",
       "      <th>dialog_per_min</th>\n",
       "      <th>genre</th>\n",
       "      <th>origin</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malcolm X</td>\n",
       "      <td>65.005208</td>\n",
       "      <td>15.072917</td>\n",
       "      <td>Romance</td>\n",
       "      <td>American</td>\n",
       "      <td>Malcolm X follows the life of African-American...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Postman Always Rings Twice</td>\n",
       "      <td>64.321429</td>\n",
       "      <td>12.973214</td>\n",
       "      <td>Romance</td>\n",
       "      <td>American</td>\n",
       "      <td>Frank Chambers (John Garfield) is a hobo who s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Transporter</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>12.351648</td>\n",
       "      <td>Crime</td>\n",
       "      <td>American</td>\n",
       "      <td>Frank Martin (Jason Statham) is a highly skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>55.365385</td>\n",
       "      <td>11.730769</td>\n",
       "      <td>Romance</td>\n",
       "      <td>American</td>\n",
       "      <td>At the last minute, a wealthy American expatri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Underworld: Awakening</td>\n",
       "      <td>42.097561</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>Action</td>\n",
       "      <td>American</td>\n",
       "      <td>A few years after the events of the second fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>Closer</td>\n",
       "      <td>57.350000</td>\n",
       "      <td>17.530000</td>\n",
       "      <td>Romance</td>\n",
       "      <td>American</td>\n",
       "      <td>In the opening scene, 24-year-old \"Alice Ayres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>High Plains Drifter</td>\n",
       "      <td>45.805825</td>\n",
       "      <td>9.475728</td>\n",
       "      <td>Western</td>\n",
       "      <td>American</td>\n",
       "      <td>A mysterious stranger rides out of the desert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>Blown Away</td>\n",
       "      <td>50.054545</td>\n",
       "      <td>11.709091</td>\n",
       "      <td>Action</td>\n",
       "      <td>American</td>\n",
       "      <td>After her mother dies in a mysterious car acci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>Ghost Town</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>10.062500</td>\n",
       "      <td>Western</td>\n",
       "      <td>American</td>\n",
       "      <td>The film begins as married New York City busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>Tamara Drewe</td>\n",
       "      <td>64.952830</td>\n",
       "      <td>15.716981</td>\n",
       "      <td>Romance</td>\n",
       "      <td>British</td>\n",
       "      <td>Set in Ewedown, a fictitious village in Dorset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2205 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  word per min  dialog_per_min    genre  \\\n",
       "0                          Malcolm X     65.005208       15.072917  Romance   \n",
       "1     The Postman Always Rings Twice     64.321429       12.973214  Romance   \n",
       "2                    The Transporter     41.000000       12.351648    Crime   \n",
       "4                            Titanic     55.365385       11.730769  Romance   \n",
       "5              Underworld: Awakening     42.097561       11.500000   Action   \n",
       "...                              ...           ...             ...      ...   \n",
       "2773                          Closer     57.350000       17.530000  Romance   \n",
       "2774             High Plains Drifter     45.805825        9.475728  Western   \n",
       "2775                      Blown Away     50.054545       11.709091   Action   \n",
       "2776                      Ghost Town     34.400000       10.062500  Western   \n",
       "2777                    Tamara Drewe     64.952830       15.716981  Romance   \n",
       "\n",
       "        origin                                               plot  \n",
       "0     American  Malcolm X follows the life of African-American...  \n",
       "1     American  Frank Chambers (John Garfield) is a hobo who s...  \n",
       "2     American  Frank Martin (Jason Statham) is a highly skill...  \n",
       "4     American  At the last minute, a wealthy American expatri...  \n",
       "5     American  A few years after the events of the second fil...  \n",
       "...        ...                                                ...  \n",
       "2773  American  In the opening scene, 24-year-old \"Alice Ayres...  \n",
       "2774  American  A mysterious stranger rides out of the desert ...  \n",
       "2775  American  After her mother dies in a mysterious car acci...  \n",
       "2776  American  The film begins as married New York City busin...  \n",
       "2777   British  Set in Ewedown, a fictitious village in Dorset...  \n",
       "\n",
       "[2205 rows x 6 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.drop_duplicates(subset='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_plot(dataset):\n",
    "    dataset['plot'] = dataset['plot'].str.replace('[^a-zA-Z]', ' ') # remove non alphabet character\n",
    "    dataset['plot'] = dataset['plot'].str.lower() # lower all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_plot(dataset):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    dataset['tokenized_text'] = dataset.apply(lambda row: nltk.word_tokenize(row['plot']), axis=1)\n",
    "    dataset['tokenized_text'] = dataset['tokenized_text'].apply(lambda word: [item for item in word if not item in stop_words])\n",
    "    dataset['tokenized_text'] = dataset['tokenized_text'].apply(lambda word: [lemmatizer.lemmatize(item) for item in word])\n",
    "    dataset['tokenized_text']=[\" \".join(text) for text in dataset['tokenized_text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_plot(df_merge)\n",
    "preprocess_plot(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>word per min</th>\n",
       "      <th>dialog_per_min</th>\n",
       "      <th>genre</th>\n",
       "      <th>origin</th>\n",
       "      <th>plot</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malcolm X</td>\n",
       "      <td>65.005208</td>\n",
       "      <td>15.072917</td>\n",
       "      <td>Romance</td>\n",
       "      <td>American</td>\n",
       "      <td>malcolm x follows the life of african american...</td>\n",
       "      <td>malcolm x follows life african american activi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Postman Always Rings Twice</td>\n",
       "      <td>64.321429</td>\n",
       "      <td>12.973214</td>\n",
       "      <td>Romance</td>\n",
       "      <td>American</td>\n",
       "      <td>frank chambers  john garfield  is a hobo who s...</td>\n",
       "      <td>frank chamber john garfield hobo stop rural di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Transporter</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>12.351648</td>\n",
       "      <td>Crime</td>\n",
       "      <td>American</td>\n",
       "      <td>frank martin  jason statham  is a highly skill...</td>\n",
       "      <td>frank martin jason statham highly skilled driv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Transporter</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>12.351648</td>\n",
       "      <td>Action</td>\n",
       "      <td>American</td>\n",
       "      <td>frank martin  jason statham  is a highly skill...</td>\n",
       "      <td>frank martin jason statham highly skilled driv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>55.365385</td>\n",
       "      <td>11.730769</td>\n",
       "      <td>Romance</td>\n",
       "      <td>American</td>\n",
       "      <td>at the last minute  a wealthy american expatri...</td>\n",
       "      <td>last minute wealthy american expatriate europe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>Closer</td>\n",
       "      <td>57.350000</td>\n",
       "      <td>17.530000</td>\n",
       "      <td>Romance</td>\n",
       "      <td>American</td>\n",
       "      <td>in the opening scene     year old  alice ayres...</td>\n",
       "      <td>opening scene year old alice ayres portman dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>High Plains Drifter</td>\n",
       "      <td>45.805825</td>\n",
       "      <td>9.475728</td>\n",
       "      <td>Western</td>\n",
       "      <td>American</td>\n",
       "      <td>a mysterious stranger rides out of the desert ...</td>\n",
       "      <td>mysterious stranger ride desert isolated minin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>Blown Away</td>\n",
       "      <td>50.054545</td>\n",
       "      <td>11.709091</td>\n",
       "      <td>Action</td>\n",
       "      <td>American</td>\n",
       "      <td>after her mother dies in a mysterious car acci...</td>\n",
       "      <td>mother dy mysterious car accident year old meg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>Ghost Town</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>10.062500</td>\n",
       "      <td>Western</td>\n",
       "      <td>American</td>\n",
       "      <td>the film begins as married new york city busin...</td>\n",
       "      <td>film begin married new york city businessman f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>Tamara Drewe</td>\n",
       "      <td>64.952830</td>\n",
       "      <td>15.716981</td>\n",
       "      <td>Romance</td>\n",
       "      <td>British</td>\n",
       "      <td>set in ewedown  a fictitious village in dorset...</td>\n",
       "      <td>set ewedown fictitious village dorset england ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2778 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  word per min  dialog_per_min    genre  \\\n",
       "0                          Malcolm X     65.005208       15.072917  Romance   \n",
       "1     The Postman Always Rings Twice     64.321429       12.973214  Romance   \n",
       "2                    The Transporter     41.000000       12.351648    Crime   \n",
       "3                    The Transporter     41.000000       12.351648   Action   \n",
       "4                            Titanic     55.365385       11.730769  Romance   \n",
       "...                              ...           ...             ...      ...   \n",
       "2773                          Closer     57.350000       17.530000  Romance   \n",
       "2774             High Plains Drifter     45.805825        9.475728  Western   \n",
       "2775                      Blown Away     50.054545       11.709091   Action   \n",
       "2776                      Ghost Town     34.400000       10.062500  Western   \n",
       "2777                    Tamara Drewe     64.952830       15.716981  Romance   \n",
       "\n",
       "        origin                                               plot  \\\n",
       "0     American  malcolm x follows the life of african american...   \n",
       "1     American  frank chambers  john garfield  is a hobo who s...   \n",
       "2     American  frank martin  jason statham  is a highly skill...   \n",
       "3     American  frank martin  jason statham  is a highly skill...   \n",
       "4     American  at the last minute  a wealthy american expatri...   \n",
       "...        ...                                                ...   \n",
       "2773  American  in the opening scene     year old  alice ayres...   \n",
       "2774  American  a mysterious stranger rides out of the desert ...   \n",
       "2775  American  after her mother dies in a mysterious car acci...   \n",
       "2776  American  the film begins as married new york city busin...   \n",
       "2777   British  set in ewedown  a fictitious village in dorset...   \n",
       "\n",
       "                                         tokenized_text  \n",
       "0     malcolm x follows life african american activi...  \n",
       "1     frank chamber john garfield hobo stop rural di...  \n",
       "2     frank martin jason statham highly skilled driv...  \n",
       "3     frank martin jason statham highly skilled driv...  \n",
       "4     last minute wealthy american expatriate europe...  \n",
       "...                                                 ...  \n",
       "2773  opening scene year old alice ayres portman dan...  \n",
       "2774  mysterious stranger ride desert isolated minin...  \n",
       "2775  mother dy mysterious car accident year old meg...  \n",
       "2776  film begin married new york city businessman f...  \n",
       "2777  set ewedown fictitious village dorset england ...  \n",
       "\n",
       "[2778 rows x 7 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_merge.drop(columns=['genre', 'title', 'plot','origin'])\n",
    "y = df_merge['genre']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730     Adventure\n",
       "887        Comedy\n",
       "2336      Western\n",
       "158         Crime\n",
       "485         Crime\n",
       "          ...    \n",
       "196        Action\n",
       "336        Action\n",
       "643        Comedy\n",
       "1793    Adventure\n",
       "2671      Romance\n",
       "Name: genre, Length: 2222, dtype: object"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "def tfidf(dataset_train, dataset_test):\n",
    "    vectorizer = TfidfVectorizer(min_df=10, max_features=20000, smooth_idf=True, norm=\"l2\", sublinear_tf=False, ngram_range=(1,4))\n",
    "    print(dataset_train.shape)\n",
    "    features_transformed = vectorizer.fit_transform(dataset_train['tokenized_text'])\n",
    "    features_test_transformed = vectorizer.transform(dataset_test['tokenized_text'])\n",
    "    \n",
    "    df_tfidf = pd.DataFrame(features_transformed.toarray(), columns=vectorizer.get_feature_names())\n",
    "    df_tfidf_test = pd.DataFrame(features_test_transformed.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "    new_df = dataset_train.drop(['tokenized_text'], axis=1).reset_index(drop=True)\n",
    "    new_test_df = dataset_test.drop(['tokenized_text'], axis=1).reset_index(drop=True)\n",
    "\n",
    "#     df_tfidf = pd.concat([df_tfidf, new_df], axis=1)\n",
    "#     df_tfidf_test = pd.concat([df_tfidf_test, new_test_df], axis=1)\n",
    "\n",
    "    return df_tfidf, df_tfidf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2222, 3)\n"
     ]
    }
   ],
   "source": [
    "tfidf_plot_train, tfidf_plot_test = tfidf(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2222, 10056)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_plot_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abby</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abducted</th>\n",
       "      <th>abduction</th>\n",
       "      <th>abducts</th>\n",
       "      <th>...</th>\n",
       "      <th>younger brother</th>\n",
       "      <th>younger self</th>\n",
       "      <th>younger sister</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youth</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2222 rows × 10056 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaron  abandon  abandoned  abandoning  abby  abdomen  abduct  abducted  \\\n",
       "0       0.0      0.0        0.0         0.0   0.0      0.0     0.0       0.0   \n",
       "1       0.0      0.0        0.0         0.0   0.0      0.0     0.0       0.0   \n",
       "2       0.0      0.0        0.0         0.0   0.0      0.0     0.0       0.0   \n",
       "3       0.0      0.0        0.0         0.0   0.0      0.0     0.0       0.0   \n",
       "4       0.0      0.0        0.0         0.0   0.0      0.0     0.0       0.0   \n",
       "...     ...      ...        ...         ...   ...      ...     ...       ...   \n",
       "2217    0.0      0.0        0.0         0.0   0.0      0.0     0.0       0.0   \n",
       "2218    0.0      0.0        0.0         0.0   0.0      0.0     0.0       0.0   \n",
       "2219    0.0      0.0        0.0         0.0   0.0      0.0     0.0       0.0   \n",
       "2220    0.0      0.0        0.0         0.0   0.0      0.0     0.0       0.0   \n",
       "2221    0.0      0.0        0.0         0.0   0.0      0.0     0.0       0.0   \n",
       "\n",
       "      abduction  abducts  ...  younger brother  younger self  younger sister  \\\n",
       "0           0.0      0.0  ...              0.0           0.0             0.0   \n",
       "1           0.0      0.0  ...              0.0           0.0             0.0   \n",
       "2           0.0      0.0  ...              0.0           0.0             0.0   \n",
       "3           0.0      0.0  ...              0.0           0.0             0.0   \n",
       "4           0.0      0.0  ...              0.0           0.0             0.0   \n",
       "...         ...      ...  ...              ...           ...             ...   \n",
       "2217        0.0      0.0  ...              0.0           0.0             0.0   \n",
       "2218        0.0      0.0  ...              0.0           0.0             0.0   \n",
       "2219        0.0      0.0  ...              0.0           0.0             0.0   \n",
       "2220        0.0      0.0  ...              0.0           0.0             0.0   \n",
       "2221        0.0      0.0  ...              0.0           0.0             0.0   \n",
       "\n",
       "      youngest     youth  zero  zeus  zombie  zone  zoo  \n",
       "0          0.0  0.000000   0.0   0.0     0.0   0.0  0.0  \n",
       "1          0.0  0.000000   0.0   0.0     0.0   0.0  0.0  \n",
       "2          0.0  0.000000   0.0   0.0     0.0   0.0  0.0  \n",
       "3          0.0  0.000000   0.0   0.0     0.0   0.0  0.0  \n",
       "4          0.0  0.000000   0.0   0.0     0.0   0.0  0.0  \n",
       "...        ...       ...   ...   ...     ...   ...  ...  \n",
       "2217       0.0  0.000000   0.0   0.0     0.0   0.0  0.0  \n",
       "2218       0.0  0.000000   0.0   0.0     0.0   0.0  0.0  \n",
       "2219       0.0  0.000000   0.0   0.0     0.0   0.0  0.0  \n",
       "2220       0.0  0.000000   0.0   0.0     0.0   0.0  0.0  \n",
       "2221       0.0  0.030874   0.0   0.0     0.0   0.0  0.0  \n",
       "\n",
       "[2222 rows x 10056 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_plot_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(C=100)\n",
    "classifier.fit(tfidf_plot_train, y_train)\n",
    "y_pred = classifier.predict(tfidf_plot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.25      0.19      0.21       112\n",
      "   Adventure       0.05      0.07      0.06        30\n",
      "      Comedy       0.20      0.19      0.20       111\n",
      "       Crime       0.36      0.31      0.33        80\n",
      "      Horror       0.38      0.50      0.43        42\n",
      "     Musical       0.12      0.45      0.20        11\n",
      "     Romance       0.41      0.26      0.32       118\n",
      "         War       0.40      0.52      0.45        33\n",
      "     Western       0.38      0.89      0.53        19\n",
      "\n",
      "    accuracy                           0.29       556\n",
      "   macro avg       0.28      0.38      0.30       556\n",
      "weighted avg       0.30      0.29      0.28       556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(learning_rate=0.01)\n",
    "xgbc.fit(tfidf_plot_train, y_train)\n",
    "ypred = xgbc.predict(tfidf_plot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.25      0.21      0.23       100\n",
      "   Adventure       0.05      0.07      0.06        29\n",
      "      Comedy       0.20      0.25      0.22        85\n",
      "       Crime       0.29      0.30      0.29        67\n",
      "      Horror       0.46      0.45      0.46        58\n",
      "     Musical       0.20      0.31      0.24        26\n",
      "     Romance       0.39      0.29      0.33       104\n",
      "         War       0.55      0.42      0.47        55\n",
      "     Western       0.49      0.69      0.57        32\n",
      "\n",
      "    accuracy                           0.31       556\n",
      "   macro avg       0.32      0.33      0.32       556\n",
      "weighted avg       0.33      0.31      0.31       556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ypred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,757,761\n",
      "Trainable params: 2,757,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000  # Only consider the top 20k words\n",
    "maxlen = 200  # Only consider the first 200 words of each movie revi\n",
    "\n",
    "# Input for variable-length sequences of integers\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = layers.Embedding(max_features, 128)(inputs)\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "# Add a classifier\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'tensorflow.python.keras.engine.data_adapter.TensorLikeDataAdapter'>, <class 'tensorflow.python.keras.engine.data_adapter.GeneratorDataAdapter'>] to handle input: <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.series.Series'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-424-3c436eb242aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_plot_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0;34m\"handling inputs. Found multiple adapters {} to handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 977\u001b[0;31m             adapter_cls, _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    978\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'tensorflow.python.keras.engine.data_adapter.TensorLikeDataAdapter'>, <class 'tensorflow.python.keras.engine.data_adapter.GeneratorDataAdapter'>] to handle input: <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.series.Series'>"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(tfidf_plot_train, y_train, batch_size=32, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ' looking mid credit scene pym show van dyne new wasp prototype suit offer post credit scene wilson steve rogers bucky barnes custody unable contact tony stark accord n wilson mention know someone hel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-419-672834881c21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m    156\u001b[0m   return sequence.pad_sequences(\n\u001b[1;32m    157\u001b[0m       \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m       padding=padding, truncating=truncating, value=value)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m keras_export(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ' looking mid credit scene pym show van dyne new wasp prototype suit offer post credit scene wilson steve rogers bucky barnes custody unable contact tony stark accord n wilson mention know someone hel"
     ]
    }
   ],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train['tokenized_text'], maxlen=maxlen)\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test['tokenized_text'], maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word per min</th>\n",
       "      <th>dialog_per_min</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>55.870690</td>\n",
       "      <td>15.534483</td>\n",
       "      <td>scientist hank pym resigns h e l discovering a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>59.670213</td>\n",
       "      <td>15.531915</td>\n",
       "      <td>steve barker johnny knoxville hate job two yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>63.162393</td>\n",
       "      <td>13.111111</td>\n",
       "      <td>miscarriage justice land willis newton prison ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>50.268817</td>\n",
       "      <td>13.451613</td>\n",
       "      <td>victor maynard bill nighy experienced efficien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>42.177419</td>\n",
       "      <td>11.774194</td>\n",
       "      <td>dr hannibal lecter attends orchestral performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>42.652482</td>\n",
       "      <td>13.297872</td>\n",
       "      <td>harry tasker lead double life wife helen daugh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>73.185185</td>\n",
       "      <td>15.546296</td>\n",
       "      <td>london british mob bos lenny cole tom wilkinso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>81.400000</td>\n",
       "      <td>22.380952</td>\n",
       "      <td>peter sanderson steve martin uptight workaholi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>26.938776</td>\n",
       "      <td>7.755102</td>\n",
       "      <td>world war ii pevensie child peter susan edmund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>69.392857</td>\n",
       "      <td>14.687500</td>\n",
       "      <td>lucy honeychurch helena bonham carter english ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2222 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word per min  dialog_per_min  \\\n",
       "730      55.870690       15.534483   \n",
       "887      59.670213       15.531915   \n",
       "2336     63.162393       13.111111   \n",
       "158      50.268817       13.451613   \n",
       "485      42.177419       11.774194   \n",
       "...            ...             ...   \n",
       "196      42.652482       13.297872   \n",
       "336      73.185185       15.546296   \n",
       "643      81.400000       22.380952   \n",
       "1793     26.938776        7.755102   \n",
       "2671     69.392857       14.687500   \n",
       "\n",
       "                                         tokenized_text  \n",
       "730   scientist hank pym resigns h e l discovering a...  \n",
       "887   steve barker johnny knoxville hate job two yea...  \n",
       "2336  miscarriage justice land willis newton prison ...  \n",
       "158   victor maynard bill nighy experienced efficien...  \n",
       "485   dr hannibal lecter attends orchestral performa...  \n",
       "...                                                 ...  \n",
       "196   harry tasker lead double life wife helen daugh...  \n",
       "336   london british mob bos lenny cole tom wilkinso...  \n",
       "643   peter sanderson steve martin uptight workaholi...  \n",
       "1793  world war ii pevensie child peter susan edmund...  \n",
       "2671  lucy honeychurch helena bonham carter english ...  \n",
       "\n",
       "[2222 rows x 3 columns]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
